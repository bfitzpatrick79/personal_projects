{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cik_list = ['1824937', '1736388', '1811231', '1446275', '1796036', '1824627', '1421744', '1588504', '1627282', '1621653', '1826050', '1742055', '1818808']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cik_list_gen():\n",
    "    cik_list = []\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    }\n",
    "    url = 'https://sec.report/CIK.rss'\n",
    "    response = requests.get(url = url, headers = headers)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    for i in soup.findAll('item'):\n",
    "        iter_list = i.title.text.split(' ')\n",
    "        cik_list.append(iter_list[-1])\n",
    "    return cik_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001836739', '0001836738', '0001836737', '0001836736', '0001836734']\n",
      "Length: 400\n"
     ]
    }
   ],
   "source": [
    "cik_list_02 = cik_list_gen()\n",
    "print(cik_list_02[0:5])\n",
    "print(f'Length: {len(cik_list_02)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_list = []\n",
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    }\n",
    "url = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent&CIK=&type=&company=&dateb=&owner=include&start=0&count=100&output=atom'\n",
    "response = requests.get(url = url, headers = headers)\n",
    "soup = BeautifulSoup(response.content)\n",
    "for i in soup.findAll('entry'):\n",
    "    iter_string = i.title.text\n",
    "    split = iter_string.split(' ')\n",
    "    string_check = []\n",
    "    for string in split:\n",
    "        if len(string) == 12:\n",
    "            string = string[1:]\n",
    "            string = string[:-1]\n",
    "            string_check.append(string)\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    cik_list.append(string_check)\n",
    "\n",
    "processed_cik = []\n",
    "for cik in cik_list:\n",
    "    processed_cik.append(cik[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(cik_list_02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to scrape and parse filings\n",
    "\n",
    "\n",
    "# returns pandas dataframe with filing information by cik\n",
    "def cik_pull(cik):\n",
    "    endpoint = r\"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "\n",
    "    # parameters dictionary\n",
    "    param_dict = {'action':'getcompany',\n",
    "                  'CIK':cik,\n",
    "                  'type':'',\n",
    "                  'dateb':'',\n",
    "                  'owner':'exclude',\n",
    "                  'start':'',\n",
    "                  'output':'atom',\n",
    "                  'count':'100'}\n",
    "\n",
    "\n",
    "    response = requests.get(url = endpoint, params = param_dict)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "    entries = soup.find_all('entry')\n",
    "\n",
    "    file_type_list = []\n",
    "    file_date_list = []\n",
    "    url_list = []\n",
    "    acc_num_list = []\n",
    "\n",
    "    for entry in entries:\n",
    "        file_type_list.append(entry.find('filing-type').text)\n",
    "        file_date_list.append(entry.find('filing-date').text)\n",
    "        acc_num_list.append(entry.find('accession-number').text)\n",
    "        url_list.append(entry.find('filing-href').text)\n",
    "    \n",
    "\n",
    "    filings_df = pd.DataFrame()\n",
    "    filings_df['file_type'] = file_type_list\n",
    "    filings_df['file_date'] = file_date_list\n",
    "    filings_df['acc_num'] = acc_num_list\n",
    "    filings_df['url'] = url_list\n",
    "\n",
    "\n",
    "    #this is for simplicity dealing with urls\n",
    "    temp_list = []\n",
    "    for i in acc_num_list:\n",
    "        temp_list.append(i.replace('-', ''))\n",
    "    filings_df['acc_num_url'] = temp_list\n",
    "    \n",
    "    return filings_df\n",
    "\n",
    "# returns dataframe of an individual filing as 1 row, and however many parsed fields as columns\n",
    "def idv_document_parse(acc_num):\n",
    "    root_url = 'https://www.sec.gov/Archives/edgar/data/'\n",
    "    cik_num = cik\n",
    "    acc_num_url = acc_num\n",
    "    xml_end = 'primary_doc.xml'\n",
    "    target_url = root_url + cik_num + '/' + acc_num_url + '/' + xml_end\n",
    "    \n",
    "    file = requests.get(target_url, timeout=20)\n",
    "    file_data = BeautifulSoup(file.content, 'lxml')\n",
    "    \n",
    "    tag_list = []\n",
    "    data_list = []\n",
    "    for i in file_data.find_all():\n",
    "        tag_list.append(i.name)\n",
    "        data_list.append(i.string)\n",
    "    file_df = pd.DataFrame(columns = tag_list)\n",
    "    data_series = pd.Series(data_list, index = file_df.columns)\n",
    "    file_df = file_df.append(data_series, ignore_index=True)\n",
    "    file_df['acc_num'] = acc_num_url\n",
    "    return file_df\n",
    "\n",
    "# given a cik, returns dictionary with key value pair of unique file type - dataframe of parsed documents of that type\n",
    "def all_files_parse(cik):\n",
    "    filings_df = cik_pull(cik)\n",
    "    \n",
    "    file_dict = {}\n",
    "    for file in filings_df['file_type'].unique():\n",
    "        target_df = pd.DataFrame()\n",
    "        iter_df = filings_df[filings_df['file_type'] == f'{file}']\n",
    "        #print(iter_df['file_type'].iloc[0])\n",
    "    \n",
    "        for i in range(len(iter_df)):\n",
    "            sub = idv_document_parse(str(iter_df['acc_num_url'].iloc[i]))\n",
    "            sub = sub.loc[:, ~sub.columns.duplicated()] #note that this will nuke the 50+ columns of jurisdiction offered.\n",
    "            target_df = target_df.append(sub).fillna(np.nan)\n",
    "        file_dict[f'{file}'] = target_df\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "0001628590\n",
      "----------------------------------------------------------------\n",
      "0001041061\n",
      "----------------------------------------------------------------\n",
      "0000049279\n",
      "----------------------------------------------------------------\n",
      "0001835333\n",
      "----------------------------------------------------------------\n",
      "0000914122\n",
      "----------------------------------------------------------------\n",
      "0001045520\n",
      "----------------------------------------------------------------\n",
      "0001081400\n",
      "----------------------------------------------------------------\n",
      "0001796467\n",
      "----------------------------------------------------------------\n",
      "0001826870\n",
      "----------------------------------------------------------------\n",
      "0001000275\n",
      "----------------------------------------------------------------\n",
      "0001419828\n",
      "----------------------------------------------------------------\n",
      "0000886982\n",
      "----------------------------------------------------------------\n",
      "0001336954\n",
      "----------------------------------------------------------------\n",
      "0001025835\n",
      "----------------------------------------------------------------\n",
      "0001082461\n",
      "----------------------------------------------------------------\n",
      "0001526787\n",
      "----------------------------------------------------------------\n",
      "0001143362\n",
      "----------------------------------------------------------------\n",
      "0001825832\n",
      "----------------------------------------------------------------\n",
      "0001835957\n",
      "----------------------------------------------------------------\n",
      "0001407933\n",
      "----------------------------------------------------------------\n",
      "0001025835\n",
      "----------------------------------------------------------------\n",
      "NDUSTRIALS\n",
      "----------------------------------------------------------------\n",
      "0001413614\n",
      "----------------------------------------------------------------\n",
      "0001315830\n",
      "----------------------------------------------------------------\n",
      "0001025835\n",
      "----------------------------------------------------------------\n",
      "0001798658\n",
      "----------------------------------------------------------------\n",
      "0001835693\n",
      "----------------------------------------------------------------\n",
      "0001710350\n",
      "----------------------------------------------------------------\n",
      "0001347962\n",
      "----------------------------------------------------------------\n",
      "0001025835\n",
      "----------------------------------------------------------------\n",
      "0001541798\n",
      "----------------------------------------------------------------\n",
      "0001025835\n",
      "----------------------------------------------------------------\n",
      "0001203646\n",
      "----------------------------------------------------------------\n",
      "0001025835\n",
      "----------------------------------------------------------------\n",
      "0001708611\n",
      "----------------------------------------------------------------\n",
      "0001602629\n",
      "----------------------------------------------------------------\n",
      "0001025835\n",
      "----------------------------------------------------------------\n",
      "0001247943\n",
      "----------------------------------------------------------------\n",
      "0000789933\n",
      "----------------------------------------------------------------\n",
      "0001832951\n",
      "----------------------------------------------------------------\n",
      "0001806524\n",
      "----------------------------------------------------------------\n",
      "0001835949\n",
      "----------------------------------------------------------------\n",
      "0001473845\n",
      "----------------------------------------------------------------\n",
      "0001473606\n",
      "----------------------------------------------------------------\n",
      "0001419828\n",
      "----------------------------------------------------------------\n",
      "0001247955\n",
      "----------------------------------------------------------------\n",
      "0000886982\n"
     ]
    },
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='www.sec.gov', port=443): Max retries exceeded with url: /Archives/edgar/data/0000789933/000078993319000004/primary_doc.xml (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000018E32086C08>, 'Connection to www.sec.gov timed out. (connect timeout=20)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 159\u001b[1;33m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mtimeout\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Connection to %s timed out. (connect timeout=%s)\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 (self.host, self.timeout))\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.VerifiedHTTPSConnection object at 0x0000018E32086C08>, 'Connection to www.sec.gov timed out. (connect timeout=20)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 638\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.sec.gov', port=443): Max retries exceeded with url: /Archives/edgar/data/0000789933/000078993319000004/primary_doc.xml (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000018E32086C08>, 'Connection to www.sec.gov timed out. (connect timeout=20)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-bab68cd3a72b>\u001b[0m in \u001b[0;36mall_files_parse\u001b[1;34m(cik)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midv_document_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_num_url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#note that this will nuke the 50+ columns of jurisdiction offered.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mtarget_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-bab68cd3a72b>\u001b[0m in \u001b[0;36midv_document_parse\u001b[1;34m(acc_num)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mtarget_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcik_num\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0macc_num_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mxml_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[0mfile_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    502\u001b[0m                 \u001b[1;31m# TODO: Remove this in 3.0.0: see #2811\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNewConnectionError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mConnectTimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='www.sec.gov', port=443): Max retries exceeded with url: /Archives/edgar/data/0000789933/000078993319000004/primary_doc.xml (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000018E32086C08>, 'Connection to www.sec.gov timed out. (connect timeout=20)'))"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "company_data_dict = {}\n",
    "\n",
    "for cik in processed_cik:\n",
    "    iter_dict = all_files_parse(cik)\n",
    "    company_data_dict[cik] = iter_dict\n",
    "    print('-'*64)\n",
    "    print(f'{cik}')\n",
    "    #for file in iter_dict.keys():\n",
    "           #print(f'#   {file}')\n",
    "    time.sleep(0.5)\n",
    "print(len(company_data_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html</th>\n",
       "      <th>body</th>\n",
       "      <th>edgarsubmission</th>\n",
       "      <th>schemaversion</th>\n",
       "      <th>submissiontype</th>\n",
       "      <th>testorlive</th>\n",
       "      <th>primaryissuer</th>\n",
       "      <th>cik</th>\n",
       "      <th>entityname</th>\n",
       "      <th>issueraddress</th>\n",
       "      <th>...</th>\n",
       "      <th>recipientaddress</th>\n",
       "      <th>statesofsolicitationlist</th>\n",
       "      <th>state</th>\n",
       "      <th>description</th>\n",
       "      <th>foreignsolicitation</th>\n",
       "      <th>isestimate</th>\n",
       "      <th>isothertype</th>\n",
       "      <th>descriptionofothertype</th>\n",
       "      <th>overfiveyears</th>\n",
       "      <th>isdebttype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X0708</td>\n",
       "      <td>D</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001835333</td>\n",
       "      <td>LD Fund I, a series of Riverside Ventures, LP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X0708</td>\n",
       "      <td>D</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001796467</td>\n",
       "      <td>Base Rate OE Fund, L.P.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X0708</td>\n",
       "      <td>D</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001835957</td>\n",
       "      <td>Questel Associes 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X0708</td>\n",
       "      <td>D</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001798658</td>\n",
       "      <td>Colorado Springs Opportunity Zone, L.L.C.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X0708</td>\n",
       "      <td>D</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001835693</td>\n",
       "      <td>RX Sidecar III, L.P.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>true</td>\n",
       "      <td>limited partnership interests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   html  body  edgarsubmission schemaversion submissiontype testorlive  \\\n",
       "0   NaN   NaN              NaN         X0708              D       LIVE   \n",
       "0   NaN   NaN              NaN         X0708              D       LIVE   \n",
       "0   NaN   NaN              NaN         X0708              D       LIVE   \n",
       "0   NaN   NaN              NaN         X0708              D       LIVE   \n",
       "0   NaN   NaN              NaN         X0708              D       LIVE   \n",
       "\n",
       "   primaryissuer         cik                                     entityname  \\\n",
       "0            NaN  0001835333  LD Fund I, a series of Riverside Ventures, LP   \n",
       "0            NaN  0001796467                        Base Rate OE Fund, L.P.   \n",
       "0            NaN  0001835957                             Questel Associes 2   \n",
       "0            NaN  0001798658      Colorado Springs Opportunity Zone, L.L.C.   \n",
       "0            NaN  0001835693                           RX Sidecar III, L.P.   \n",
       "\n",
       "   issueraddress  ... recipientaddress statesofsolicitationlist state  \\\n",
       "0            NaN  ...              NaN                      NaN   NaN   \n",
       "0            NaN  ...              NaN                      NaN   NaN   \n",
       "0            NaN  ...              NaN                      NaN   NaN   \n",
       "0            NaN  ...              NaN                      NaN    CA   \n",
       "0            NaN  ...              NaN                      NaN   NaN   \n",
       "\n",
       "  description foreignsolicitation isestimate isothertype  \\\n",
       "0         NaN                 NaN        NaN         NaN   \n",
       "0         NaN                 NaN        NaN         NaN   \n",
       "0         NaN                 NaN        NaN         NaN   \n",
       "0  CALIFORNIA               false       true         NaN   \n",
       "0         NaN                 NaN        NaN        true   \n",
       "\n",
       "          descriptionofothertype  overfiveyears isdebttype  \n",
       "0                            NaN            NaN        NaN  \n",
       "0                            NaN            NaN        NaN  \n",
       "0                            NaN            NaN        NaN  \n",
       "0                            NaN            NaN        NaN  \n",
       "0  limited partnership interests            NaN        NaN  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this generates a dictionary for each unique filetype. It is structured similarly to the above, but more efficient to work with for slicing into tables.\n",
    "\n",
    "all_filing_types = []\n",
    "filing_dict = {}\n",
    "\n",
    "for key in company_data_dict.keys():\n",
    "    for file in company_data_dict[key]:\n",
    "        all_filing_types.append(file)\n",
    "\n",
    "all_filing_types = set(all_filing_types) #gives all unique file types across all ciks pulled\n",
    "all_filing_types = list(all_filing_types)\n",
    "for i in all_filing_types:\n",
    "     filing_dict[i] = pd.DataFrame()\n",
    "\n",
    "for key in company_data_dict.keys():\n",
    "    for file in company_data_dict[key]:\n",
    "        filing_dict[file] = filing_dict[file].append(company_data_dict[key][file])\n",
    "        \n",
    "filing_dict['D'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies for transforming data into tables for export\n",
    "import json\n",
    "import sqlalchemy as SQL\n",
    "import pymongo\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables\n",
    "\n",
    "filings_table = pd.DataFrame() # PK acc_num, FK CIK num, file_type, date_filed\n",
    "\n",
    "company_table = pd.DataFrame() #PK CIK - name, address, phone number, contact information\n",
    "    # maybe split contact information from customer\n",
    "issuer_table = pd.DataFrame() #PK acc_number FK CIK - name, address, legal status\n",
    "financial_table_C = pd.DataFrame() # PK acc_number\n",
    "financial_table_C_A = pd.DataFrame()\n",
    "financial_table_D = pd.DataFrame() # PK acc_number\n",
    "financial_table_1_A = pd.DataFrame() # PK acc_number\n",
    "financial_table_1_A_A = pd.DataFrame()\n",
    "\n",
    "# returns list of keys that provide dataframes with data, corresponding to what files have an xml file on EDGAR\n",
    "all_dfs = set(filing_dict.keys())\n",
    "error_dfs = set(['DOS', '1-A-W', 'CORRESP', '1-U', 'UPLOAD', 'DOSLTR', 'DOS/A', 'REGDEX', '253G2', '1-SA', 'QUALIF']) #QUALIF is odd and needs attention\n",
    "error_dfs = []\n",
    "\n",
    "\n",
    "success_dfs =  list(all_dfs - error_dfs)\n",
    "success_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for reference of the index of columns in each file type for use in splicing. This cell will get deleted when it isn't needed anymore.\n",
    "for i in success_dfs:\n",
    "    counter = 0\n",
    "    print('')\n",
    "    print(f'--- {i}---')\n",
    "    for i in filing_dict[i].columns:\n",
    "        print(f'index {counter} - {i}')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filings table\n",
    "\n",
    "\"\"\"\n",
    "This is going to need more cleanup. Due to the other types of documents within the data ingest, a try-except needs to be implemented for each one.\n",
    "for the moment, this is proof of concept for how the tables will fit together in the schema, and how it flows from EDGAR into these tables then into mongo or SQL.\n",
    "The other filings are just going to need closer attention to decide if parsing some of the .txt documents are worth it, or if they should just ignored.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for i in success_dfs:\n",
    "    iter_df = pd.DataFrame()\n",
    "    \n",
    "    iter_df['acc_num'] = filing_dict[i]['acc_num']\n",
    "    try:\n",
    "        iter_df['cik'] = filing_dict[i]['cik']\n",
    "    except:\n",
    "        iter_df['cik'] = filing_dict[i]['filercik']\n",
    "    iter_df['filing_type'] = filing_dict[i]['submissiontype']\n",
    "    filings_table = filings_table.append(iter_df, ignore_index=True)\n",
    "    \n",
    "    \n",
    "print(filings_table)\n",
    "\n",
    "#filing table to json for mongo, creates list of dictionaries, one for each row.\n",
    "filings_json = json.loads(filings_table.to_json(orient='records'))\n",
    "\n",
    "print(filings_json[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-A processing\n",
    "#  financials slice - filing_dict['1-A'].iloc[:,27:64]\n",
    "# issuer_slice - filing_dict['1-A'].iloc[:,4:26]\n",
    "\n",
    "issuer_table = issuer_table.append(filing_dict['1-A'].iloc[:, 4:26])\n",
    "issuer_table['acc_num'] = filing_dict['1-A']['acc_num']\n",
    "financial_table_1_A = financial_table_1_A.append(filing_dict['1-A'].iloc[:, 27:63])\n",
    "financial_table_1_A = financial_table_1_A.append(filing_dict['1-A/A'].iloc[:, 30:62])\n",
    "#financial_table_1_A['acc_num'] = filing_dict['1-A']['acc_num']\n",
    "\n",
    "financial_1_A_json = json.loads(financial_table_1_A.to_json(orient='records'))\n",
    "    \n",
    "financial_table_1_A.head().transpose()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C processing\n",
    "\n",
    "financial_table_C = financial_table_C.append(filing_dict['C'].iloc[:, 33:67])\n",
    "financial_C_json = json.loads(financial_table_C.to_json(orient='records'))\n",
    "financial_table_C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D processing\n",
    "\n",
    "financial_table_D = financial_table_C.append(filing_dict['D'].iloc[:, 33:67])\n",
    "financial_D_json = json.loads(financial_table_D.to_json(orient='records'))\n",
    "financial_table_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing insertion into mongo\n",
    "\n",
    "api_string = 'mongodb+srv://fitz:Fearfulsymmetry99@ssa-data.xspaw.mongodb.net/<dbname>?retryWrites=true&w=majority'\n",
    "cluster = MongoClient(api_string)\n",
    "\n",
    "db = cluster['ssa-data'] #personal cluster, will change to company when ready for launch\n",
    "collection_filings = db['filing-data']\n",
    "collection_financial_1_A = db['financials-1-A']\n",
    "collection_financial_C = db['financials-C']\n",
    "collection_financial_D = db['financials-D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_filings.insert_many(filings_json)\n",
    "collection_financial_1_A.insert_many(financial_1_A_json)\n",
    "collection_financial_C.insert_many(financial_C_json)\n",
    "collection_financial_D.insert_many(financial_D_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_cik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
