{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_list = ['0001786874']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to scrape and parse filings\n",
    "\n",
    "\n",
    "# returns pandas dataframe with filing information by cik\n",
    "def cik_pull(cik):\n",
    "    endpoint = r\"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "\n",
    "    # parameters dictionary\n",
    "    param_dict = {'action':'getcompany',\n",
    "                  'CIK':cik,\n",
    "                  'type':'',\n",
    "                  'dateb':'',\n",
    "                  'owner':'exclude',\n",
    "                  'start':'',\n",
    "                  'output':'atom',\n",
    "                  'count':'100'}\n",
    "\n",
    "\n",
    "    response = requests.get(url = endpoint, params = param_dict)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "    entries = soup.find_all('entry')\n",
    "\n",
    "    file_type_list = []\n",
    "    file_date_list = []\n",
    "    url_list = []\n",
    "    acc_num_list = []\n",
    "\n",
    "    for entry in entries:\n",
    "        file_type_list.append(entry.find('filing-type').text)\n",
    "        file_date_list.append(entry.find('filing-date').text)\n",
    "        acc_num_list.append(entry.find('accession-number').text)\n",
    "        url_list.append(entry.find('filing-href').text)\n",
    "    \n",
    "\n",
    "    filings_df = pd.DataFrame()\n",
    "    filings_df['file_type'] = file_type_list\n",
    "    filings_df['file_date'] = file_date_list\n",
    "    filings_df['acc_num'] = acc_num_list\n",
    "    filings_df['url'] = url_list\n",
    "\n",
    "\n",
    "    #this is for simplicity dealing with urls\n",
    "    temp_list = []\n",
    "    for i in acc_num_list:\n",
    "        temp_list.append(i.replace('-', ''))\n",
    "    filings_df['acc_num_url'] = temp_list\n",
    "    \n",
    "    return filings_df\n",
    "\n",
    "# returns dataframe of an individual filing as 1 row, and however many parsed fields as columns\n",
    "def idv_document_parse(acc_num):\n",
    "    root_url = 'https://www.sec.gov/Archives/edgar/data/'\n",
    "    cik_num = cik\n",
    "    acc_num_url = acc_num\n",
    "    xml_end = 'primary_doc.xml'\n",
    "    target_url = root_url + cik_num + '/' + acc_num_url + '/' + xml_end\n",
    "    \n",
    "    file = requests.get(target_url)\n",
    "    file_data = BeautifulSoup(file.content, 'lxml')\n",
    "    \n",
    "    tag_list = []\n",
    "    data_list = []\n",
    "    for i in file_data.find_all():\n",
    "        tag_list.append(i.name)\n",
    "        data_list.append(i.string)\n",
    "    file_df = pd.DataFrame(columns = tag_list)\n",
    "    data_series = pd.Series(data_list, index = file_df.columns)\n",
    "    file_df = file_df.append(data_series, ignore_index=True)\n",
    "    return file_df\n",
    "\n",
    "# given a cik, returns dictionary with key value pair of unique file type - dataframe of parsed documents of that type\n",
    "def all_files_parse(cik):\n",
    "    filings_df = cik_pull(cik)\n",
    "    \n",
    "    file_dict = {}\n",
    "    for file in filings_df['file_type'].unique():\n",
    "        target_df = pd.DataFrame()\n",
    "        iter_df = filings_df[filings_df['file_type'] == f'{file}']\n",
    "        print(iter_df['file_type'].iloc[0])\n",
    "    \n",
    "        for i in range(len(iter_df)):\n",
    "            sub = idv_document_parse(str(iter_df['acc_num_url'].iloc[i]))\n",
    "            sub = sub.loc[:, ~sub.columns.duplicated()] #note that this will nuke the 50+ columns of jurisdiction offered.\n",
    "            target_df = target_df.append(sub).fillna(np.nan)\n",
    "        file_dict[f'{file}'] = target_df\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "company_data_dict = {}\n",
    "\n",
    "for cik in cik_list:\n",
    "    iter_dict = all_files_parse(cik)\n",
    "    company_data_dict[cik] = iter_dict\n",
    "    print('-'*64)\n",
    "    print(f'{cik})\n",
    "    for file in iter_dict.keys():\n",
    "          print(f'#   {file}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
