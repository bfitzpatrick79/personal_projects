{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_list = ['1824937', '1736388', '1811231', '1446275', '1796036', '1824627', '1421744', '1588504', '1627282', '1621653', '1826050', '1742055', '1818808']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to scrape and parse filings\n",
    "\n",
    "\n",
    "# returns pandas dataframe with filing information by cik\n",
    "def cik_pull(cik):\n",
    "    endpoint = r\"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "\n",
    "    # parameters dictionary\n",
    "    param_dict = {'action':'getcompany',\n",
    "                  'CIK':cik,\n",
    "                  'type':'',\n",
    "                  'dateb':'',\n",
    "                  'owner':'exclude',\n",
    "                  'start':'',\n",
    "                  'output':'atom',\n",
    "                  'count':'100'}\n",
    "\n",
    "\n",
    "    response = requests.get(url = endpoint, params = param_dict)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "    entries = soup.find_all('entry')\n",
    "\n",
    "    file_type_list = []\n",
    "    file_date_list = []\n",
    "    url_list = []\n",
    "    acc_num_list = []\n",
    "\n",
    "    for entry in entries:\n",
    "        file_type_list.append(entry.find('filing-type').text)\n",
    "        file_date_list.append(entry.find('filing-date').text)\n",
    "        acc_num_list.append(entry.find('accession-number').text)\n",
    "        url_list.append(entry.find('filing-href').text)\n",
    "    \n",
    "\n",
    "    filings_df = pd.DataFrame()\n",
    "    filings_df['file_type'] = file_type_list\n",
    "    filings_df['file_date'] = file_date_list\n",
    "    filings_df['acc_num'] = acc_num_list\n",
    "    filings_df['url'] = url_list\n",
    "\n",
    "\n",
    "    #this is for simplicity dealing with urls\n",
    "    temp_list = []\n",
    "    for i in acc_num_list:\n",
    "        temp_list.append(i.replace('-', ''))\n",
    "    filings_df['acc_num_url'] = temp_list\n",
    "    \n",
    "    return filings_df\n",
    "\n",
    "# returns dataframe of an individual filing as 1 row, and however many parsed fields as columns\n",
    "def idv_document_parse(acc_num):\n",
    "    root_url = 'https://www.sec.gov/Archives/edgar/data/'\n",
    "    cik_num = cik\n",
    "    acc_num_url = acc_num\n",
    "    xml_end = 'primary_doc.xml'\n",
    "    target_url = root_url + cik_num + '/' + acc_num_url + '/' + xml_end\n",
    "    \n",
    "    file = requests.get(target_url)\n",
    "    file_data = BeautifulSoup(file.content, 'lxml')\n",
    "    \n",
    "    tag_list = []\n",
    "    data_list = []\n",
    "    for i in file_data.find_all():\n",
    "        tag_list.append(i.name)\n",
    "        data_list.append(i.string)\n",
    "    file_df = pd.DataFrame(columns = tag_list)\n",
    "    data_series = pd.Series(data_list, index = file_df.columns)\n",
    "    file_df = file_df.append(data_series, ignore_index=True)\n",
    "    file_df['acc_num'] = acc_num_url\n",
    "    return file_df\n",
    "\n",
    "# given a cik, returns dictionary with key value pair of unique file type - dataframe of parsed documents of that type\n",
    "def all_files_parse(cik):\n",
    "    filings_df = cik_pull(cik)\n",
    "    \n",
    "    file_dict = {}\n",
    "    for file in filings_df['file_type'].unique():\n",
    "        target_df = pd.DataFrame()\n",
    "        iter_df = filings_df[filings_df['file_type'] == f'{file}']\n",
    "        #print(iter_df['file_type'].iloc[0])\n",
    "    \n",
    "        for i in range(len(iter_df)):\n",
    "            sub = idv_document_parse(str(iter_df['acc_num_url'].iloc[i]))\n",
    "            sub = sub.loc[:, ~sub.columns.duplicated()] #note that this will nuke the 50+ columns of jurisdiction offered.\n",
    "            target_df = target_df.append(sub).fillna(np.nan)\n",
    "        file_dict[f'{file}'] = target_df\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "1824937\n",
      "#   C\n",
      "----------------------------------------------------------------\n",
      "1736388\n",
      "#   C/A\n",
      "#   C-AR\n",
      "#   C\n",
      "#   D\n",
      "#   C-U\n",
      "#   C-AR/A\n",
      "----------------------------------------------------------------\n",
      "1811231\n",
      "#   D\n",
      "#   C/A\n",
      "#   C\n",
      "----------------------------------------------------------------\n",
      "1446275\n",
      "#   1-SA\n",
      "#   253G2\n",
      "#   QUALIF\n",
      "#   CORRESP\n",
      "#   UPLOAD\n",
      "#   1-A/A\n",
      "#   C-AR/A\n",
      "#   1-A\n",
      "#   C-AR\n",
      "#   C-U\n",
      "#   D\n",
      "#   C\n",
      "#   D/A\n",
      "#   C/A\n",
      "#   REGDEX\n",
      "----------------------------------------------------------------\n",
      "1796036\n",
      "#   C/A\n",
      "#   C-AR\n",
      "#   C\n",
      "----------------------------------------------------------------\n",
      "1824627\n",
      "#   C\n",
      "----------------------------------------------------------------\n",
      "1421744\n",
      "#   253G2\n",
      "#   QUALIF\n",
      "#   CORRESP\n",
      "#   1-A/A\n",
      "#   UPLOAD\n",
      "#   1-A\n",
      "#   C-AR\n",
      "#   D\n",
      "#   C-U\n",
      "#   C\n",
      "#   D/A\n",
      "#   REGDEX\n",
      "----------------------------------------------------------------\n",
      "1588504\n",
      "#   1-A-W\n",
      "#   1-SA\n",
      "#   253G2\n",
      "#   QUALIF\n",
      "#   CORRESP\n",
      "#   1-A/A\n",
      "#   UPLOAD\n",
      "#   1-U\n",
      "#   1-K\n",
      "#   1-A\n",
      "#   1-A POS\n",
      "#   1-K/A\n",
      "----------------------------------------------------------------\n",
      "1627282\n",
      "#   1-U\n",
      "#   253G2\n",
      "#   1-SA\n",
      "#   QUALIF\n",
      "#   1-A POS\n",
      "#   1-K\n",
      "#   CORRESP\n",
      "#   UPLOAD\n",
      "#   1-A/A\n",
      "#   1-A-W\n",
      "#   1-A\n",
      "#   DOS/A\n",
      "#   DOSLTR\n",
      "#   DOS\n",
      "#   D/A\n",
      "#   D\n",
      "----------------------------------------------------------------\n",
      "1621653\n",
      "#   C\n",
      "#   D\n",
      "#   D/A\n",
      "----------------------------------------------------------------\n",
      "1826050\n",
      "#   C\n",
      "----------------------------------------------------------------\n",
      "1742055\n",
      "#   C/A\n",
      "#   C\n",
      "#   C-AR\n",
      "#   C-U\n",
      "----------------------------------------------------------------\n",
      "1818808\n",
      "#   C/A\n",
      "#   C\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "company_data_dict = {}\n",
    "\n",
    "for cik in cik_list:\n",
    "    iter_dict = all_files_parse(cik)\n",
    "    company_data_dict[cik] = iter_dict\n",
    "    print('-'*64)\n",
    "    print(f'{cik}')\n",
    "    for file in iter_dict.keys():\n",
    "          print(f'#   {file}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1824937', '1736388', '1811231', '1446275', '1796036', '1824627', '1421744', '1588504', '1627282', '1621653', '1826050', '1742055', '1818808'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html</th>\n",
       "      <th>body</th>\n",
       "      <th>edgarsubmission</th>\n",
       "      <th>headerdata</th>\n",
       "      <th>submissiontype</th>\n",
       "      <th>filerinfo</th>\n",
       "      <th>filer</th>\n",
       "      <th>filercredentials</th>\n",
       "      <th>filercik</th>\n",
       "      <th>filerccc</th>\n",
       "      <th>...</th>\n",
       "      <th>issuer</th>\n",
       "      <th>issuertitle</th>\n",
       "      <th>signaturepersons</th>\n",
       "      <th>signatureperson</th>\n",
       "      <th>personsignature</th>\n",
       "      <th>persontitle</th>\n",
       "      <th>signaturedate</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>crdnumber</th>\n",
       "      <th>com:street2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001824937</td>\n",
       "      <td>XXXXXXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>Shacksbury Holdings, Inc.</td>\n",
       "      <td>President, CEO, Principal Financial Officer, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colin Davis</td>\n",
       "      <td>President, CEO, Principal Financial Officer, C...</td>\n",
       "      <td>09-29-2020</td>\n",
       "      <td>000166516020001215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001736388</td>\n",
       "      <td>XXXXXXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>R3 Printing, Inc.</td>\n",
       "      <td>Director; Treasurer; Head of Product; Chief Ex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Petra Wood</td>\n",
       "      <td>Director; Vice President; Head of Growth; Chie...</td>\n",
       "      <td>03-17-2020</td>\n",
       "      <td>000166516020000248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001736388</td>\n",
       "      <td>XXXXXXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>R3 Printing, Inc.</td>\n",
       "      <td>President</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Daniel Downs</td>\n",
       "      <td>Director</td>\n",
       "      <td>05-20-2019</td>\n",
       "      <td>000173638819000005</td>\n",
       "      <td>283874</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001736388</td>\n",
       "      <td>XXXXXXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>R3 Printing, Inc.</td>\n",
       "      <td>President</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Daniel Downs</td>\n",
       "      <td>Director</td>\n",
       "      <td>04-11-2018</td>\n",
       "      <td>000173638818000001</td>\n",
       "      <td>283874</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001811231</td>\n",
       "      <td>XXXXXXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>Solectrac, Inc.</td>\n",
       "      <td>CEO, Principal Executive Officer and Director,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stephen Heckeroth</td>\n",
       "      <td>CEO, Principal Executive Officer and Director,...</td>\n",
       "      <td>05-28-2020</td>\n",
       "      <td>000166516020000670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   html  body  edgarsubmission  headerdata submissiontype  filerinfo  filer  \\\n",
       "0   NaN   NaN              NaN         NaN              C        NaN    NaN   \n",
       "0   NaN   NaN              NaN         NaN              C        NaN    NaN   \n",
       "0   NaN   NaN              NaN         NaN              C        NaN    NaN   \n",
       "0   NaN   NaN              NaN         NaN              C        NaN    NaN   \n",
       "0   NaN   NaN              NaN         NaN              C        NaN    NaN   \n",
       "\n",
       "   filercredentials    filercik  filerccc  ...                     issuer  \\\n",
       "0               NaN  0001824937  XXXXXXXX  ...  Shacksbury Holdings, Inc.   \n",
       "0               NaN  0001736388  XXXXXXXX  ...          R3 Printing, Inc.   \n",
       "0               NaN  0001736388  XXXXXXXX  ...          R3 Printing, Inc.   \n",
       "0               NaN  0001736388  XXXXXXXX  ...          R3 Printing, Inc.   \n",
       "0               NaN  0001811231  XXXXXXXX  ...            Solectrac, Inc.   \n",
       "\n",
       "                                         issuertitle signaturepersons  \\\n",
       "0  President, CEO, Principal Financial Officer, C...              NaN   \n",
       "0  Director; Treasurer; Head of Product; Chief Ex...              NaN   \n",
       "0                                          President              NaN   \n",
       "0                                          President              NaN   \n",
       "0  CEO, Principal Executive Officer and Director,...              NaN   \n",
       "\n",
       "  signatureperson    personsignature  \\\n",
       "0             NaN        Colin Davis   \n",
       "0             NaN         Petra Wood   \n",
       "0             NaN       Daniel Downs   \n",
       "0             NaN       Daniel Downs   \n",
       "0             NaN  Stephen Heckeroth   \n",
       "\n",
       "                                         persontitle  signaturedate  \\\n",
       "0  President, CEO, Principal Financial Officer, C...     09-29-2020   \n",
       "0  Director; Vice President; Head of Growth; Chie...     03-17-2020   \n",
       "0                                           Director     05-20-2019   \n",
       "0                                           Director     04-11-2018   \n",
       "0  CEO, Principal Executive Officer and Director,...     05-28-2020   \n",
       "\n",
       "              acc_num crdnumber  com:street2  \n",
       "0  000166516020001215       NaN          NaN  \n",
       "0  000166516020000248       NaN          NaN  \n",
       "0  000173638819000005    283874          NaN  \n",
       "0  000173638818000001    283874          NaN  \n",
       "0  000166516020000670       NaN          NaN  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this generates a dictionary for each unique filetype. It is structured similarly to the above, but more efficient to work with for slicing into tables.\n",
    "\n",
    "all_filing_types = []\n",
    "filing_dict = {}\n",
    "\n",
    "for key in company_data_dict.keys():\n",
    "    for file in company_data_dict[key]:\n",
    "        all_filing_types.append(file)\n",
    "\n",
    "all_filing_types = set(all_filing_types) #gives all unique file types across all ciks pulled\n",
    "all_filing_types = list(all_filing_types)\n",
    "for i in all_filing_types:\n",
    "     filing_dict[i] = pd.DataFrame()\n",
    "\n",
    "for key in company_data_dict.keys():\n",
    "    for file in company_data_dict[key]:\n",
    "        filing_dict[file] = filing_dict[file].append(company_data_dict[key][file])\n",
    "        \n",
    "filing_dict['C'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies for transforming data into tables for export\n",
    "import json\n",
    "import sqlalchemy as SQL\n",
    "import pymongo\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C-AR',\n",
       " '1-A POS',\n",
       " 'C/A',\n",
       " '1-A',\n",
       " 'D/A',\n",
       " '1-K/A',\n",
       " 'C-AR/A',\n",
       " '1-A/A',\n",
       " 'C-U',\n",
       " '1-K',\n",
       " 'D',\n",
       " 'C']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tables\n",
    "\n",
    "filings_table = pd.DataFrame() # PK acc_num, FK CIK num, file_type, date_filed\n",
    "\n",
    "company_table = pd.DataFrame() #PK CIK - name, address, phone number, contact information\n",
    "    # maybe split contact information from customer\n",
    "issuer_table = pd.DataFrame() #PK acc_number FK CIK - name, address, legal status\n",
    "financial_table_C = pd.DataFrame() # PK acc_number\n",
    "financial_table_D = pd.DataFrame() # PK acc_number\n",
    "financial_table_1_A = pd.DataFrame() # PK acc_number\n",
    "\n",
    "# returns list of keys that provide dataframes with data, corresponding to what files have an xml file on EDGAR\n",
    "all_dfs = set(filing_dict.keys())\n",
    "error_dfs = set(['DOS', '1-A-W', 'CORRESP', '1-U', 'UPLOAD', 'DOSLTR', 'DOS/A', 'REGDEX', '253G2', '1-SA', 'QUALIF']) #QUALIF is odd and needs attention\n",
    "success_dfs =  list(all_dfs - error_dfs)\n",
    "success_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for reference of the index of columns in each file type for use in splicing. This cell will get deleted when it isn't needed anymore.\n",
    "for i in success_dfs:\n",
    "    counter = 0\n",
    "    print('')\n",
    "    print(f'--- {i}---')\n",
    "    for i in filing_dict[i].columns:\n",
    "        print(f'index {counter} - {i}')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filings table\n",
    "\n",
    "\"\"\"\n",
    "This is going to need more cleanup. Due to the other types of documents within the data ingest, a try-except needs to be implemented for each one.\n",
    "for the moment, this is proof of concept for how the tables will fit together in the schema, and how it flows from EDGAR into these tables then into mongo or SQL.\n",
    "The other filings are just going to need closer attention to decide if parsing some of the .txt documents are worth it, or if they should just ignored.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for i in success_dfs:\n",
    "    iter_df = pd.DataFrame()\n",
    "    \n",
    "    iter_df['acc_num'] = filing_dict[i]['acc_num']\n",
    "    try:\n",
    "        iter_df['cik'] = filing_dict[i]['cik']\n",
    "    except:\n",
    "        iter_df['cik'] = filing_dict[i]['filercik']\n",
    "    iter_df['filing_type'] = filing_dict[i]['submissiontype']\n",
    "    filings_table = filings_table.append(iter_df, ignore_index=True)\n",
    "    \n",
    "    \n",
    "print(filings_table)\n",
    "\n",
    "#filing table to json for mongo, creates list of dictionaries, one for each row.\n",
    "filings_json = json.loads(filings_table.to_json(orient='records'))\n",
    "\n",
    "print(filings_json[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing insertion into mongo\n",
    "\n",
    "api_string = 'mongodb+srv://fitz:Fearfulsymmetry99@ssa-data.xspaw.mongodb.net/<dbname>?retryWrites=true&w=majority'\n",
    "cluster = MongoClient(api_string)\n",
    "\n",
    "db = cluster['ssa-data'] #personal cluster, will change to company when ready for production\n",
    "collection = db['filing-data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.insert_many(filings_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = collection.find({\"filing_type\" : \"C\"})\n",
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_table\n",
    "company_files = ['C', 'D', '1-A']\n",
    "company_ciks = []\n",
    "\n",
    "for i in company_data_dict.keys():\n",
    "    company_ciks.append(i)\n",
    "    for x in company_data_dict[i].keys():\n",
    "        print(type(company_data_dict[i][x]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_cik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
